{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGINNING OF PROGRAM\n",
      "\n",
      "Suggest dropping these columns: \n",
      " ['mths_since_last_delinq', 'mths_since_last_record', 'next_payment_date', 'mths_since_last_major_derog']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 57\u001b[0m\n\u001b[0;32m     52\u001b[0m     dataframe \u001b[38;5;241m=\u001b[39m column_drop(dataframe, acceptable_null_percentage)\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataframe\n\u001b[1;32m---> 57\u001b[0m dataframe, suggested_drops \u001b[38;5;241m=\u001b[39m \u001b[43minitial_general_cleanup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatacsv_df\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#performs cleanup\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m#dont want to type in 80 twice.\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m#TODO: find a way to link the first typing of 80\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m#      to both the function which displays the suggested\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m \n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m#dataframe = imputing(dataframe)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 51\u001b[0m, in \u001b[0;36minitial_general_cleanup\u001b[1;34m(dataframe)\u001b[0m\n\u001b[0;32m     48\u001b[0m dataframe \u001b[38;5;241m=\u001b[39m DT\u001b[38;5;241m.\u001b[39mto_int(dataframe, list_of_to_int)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m#Drop Null columns under X%:\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m suggested_drops, acceptable_null_percentage \u001b[38;5;241m=\u001b[39m display_suggested_drops(dataframe)\n\u001b[0;32m     52\u001b[0m dataframe \u001b[38;5;241m=\u001b[39m column_drop(dataframe, acceptable_null_percentage)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataframe\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "from RDSDatabaseConnector import RDSDatabaseConnector\n",
    "from Plotter import Plotter\n",
    "from DataTransform import DataTransform\n",
    "from DataFrameTransform import DataFrameTransform\n",
    "from DataFrameInfo import DataFrameInfo\n",
    "from functions import display_suggested_drops, column_drop\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "RDSD = RDSDatabaseConnector()\n",
    "PL = Plotter()\n",
    "DT = DataTransform()\n",
    "DFT = DataFrameTransform()\n",
    "DFI = DataFrameInfo()\n",
    "\n",
    "print(\"BEGINNING OF PROGRAM\\n\")\n",
    "\n",
    "datacsv_df = pd.read_csv('data.csv') #define dataframe\n",
    "all_columns = list(datacsv_df.columns) #define list of all columns in dataframe\n",
    "\n",
    "#columns to convert to the various formats:\n",
    "list_of_to_categorical = ['term','grade','sub_grade', 'employment_length','home_ownership','verification_status','loan_status','payment_plan','purpose','delinq_2yrs','application_type']\n",
    "list_of_to_boolean = ['policy_code']\n",
    "list_of_to_float = []\n",
    "list_of_to_int = []\n",
    "date_columns = ['issue_date','earliest_credit_line','last_payment_date','next_payment_date','last_credit_pull_date']\n",
    "\n",
    "def initial_general_cleanup(dataframe: pd.core.frame.DataFrame):\n",
    "    \"\"\"Perform cleanup.\n",
    "    Specific cleanup processes to\n",
    "    be listed here in detail:\n",
    "    \n",
    "    Perform Conversions - dates, categorical, boolean, float, int\n",
    "    Perform\n",
    "    \n",
    "    Drop Null columns under X% full of rows\n",
    "    \n",
    "    args:\n",
    "    dataframe (type: pd.core.frame.DataFrame)\n",
    "    \n",
    "    \"\"\"\n",
    "    #Column Conversions:\n",
    "    dataframe = DT.convert_dates_to_proper_format(dataframe, date_columns, format = '%b-%Y') # %b is Jan/Feb/Mar etc\n",
    "    dataframe = DT.to_categorical(dataframe, list_of_to_categorical)\n",
    "    dataframe = DT.to_boolean(dataframe, list_of_to_boolean)\n",
    "    dataframe = DT.to_float(dataframe, list_of_to_float)\n",
    "    dataframe = DT.to_int(dataframe, list_of_to_int)\n",
    "    \n",
    "    #Drop Null columns under X%:\n",
    "    suggested_drops, acceptable_null_percentage = display_suggested_drops(dataframe)\n",
    "    dataframe = column_drop(dataframe, acceptable_null_percentage)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "dataframe, suggested_drops = initial_general_cleanup(datacsv_df) #performs cleanup\n",
    "print\n",
    "\n",
    "\n",
    "#dont want to type in 80 twice.\n",
    "#TODO: find a way to link the first typing of 80\n",
    "#      to both the function which displays the suggested\n",
    "#      columns to drop and the function which drops them\n",
    "# 80 goes to variable 'acceptable_null_percentage'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#dataframe = imputing(dataframe)\n",
    "'''dataframe = DataFrameInfo_class_method_execution(dataframe)\n",
    "\n",
    "    def describe_all_columns_to_check_their_datatypes(self, df:pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "        \"\"\"Describe all columns in the DataFrame to check their data types.\n",
    "\n",
    "        Args:\n",
    "            df (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        print(df.dtypes)\n",
    "        return df\n",
    "    \n",
    "    def extract_statistical_values_median_stddev_mean_from_cols_and_dataframe(self, df:pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "        \"\"\"Extract statistical values: median, standard deviation and mean from the columns and the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            df (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        print(df.describe()) # gives everything but the median.\n",
    "        print('Medians for each column: \\n')\n",
    "        print(df.median(numeric_only=True))\n",
    "        return df\n",
    "    \n",
    "    def count_distinct_values_in_categorical_columns(self, df:pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "        \"\"\"Count distinct values in categorical columns.\n",
    "\n",
    "        Args:\n",
    "            df (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        print(df.nunique())\n",
    "        return df\n",
    "    \n",
    "    def print_out_the_shape_of_the_dataframe(self, df:pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "        \"\"\"Print out the shape of the DataFrame.\n",
    "\n",
    "        Args:\n",
    "            df (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        print(df.shape)\n",
    "        return df\n",
    "    \n",
    "    def generate_a_count_slash_percentage_count_of_NULL_values_in_each_column(self, df:pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "        \"\"\"Generate a count/percentage count of NULL values in each column.\n",
    "\n",
    "        Args:\n",
    "            df (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"        \"\"\"\"\"\"\n",
    "        for element in df:\n",
    "            non_null_count = df[element].count()\n",
    "            total_count = df.shape[0]\n",
    "            percentage_non_null = (non_null_count / total_count) * 100\n",
    "            print(element, ': Non-nulls:', non_null_count, 'Non-Null Percentage:', percentage_non_null, '%')\n",
    "        return df\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "#dataframe = apply_skew_correction(dataframe)\n",
    "#dataframe = remove_excess_symbols(dataframe)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n\",\"END OF PROGRAM\")\n",
    "\n",
    "\n",
    "\n",
    "#print(all_columns)\n",
    "\"\"\"Milestone 4 Task 1\n",
    "    Step 1: Summarise currently what percentage of the loans are recovered against the investor \n",
    "            funding and the total amount funded. Visualise your results on an appropriate graph.\n",
    "            \n",
    "    Step 2: Additionally visualise what percentage of the total amount would be recovered up to\n",
    "            6 months' in the future.\n",
    "            \n",
    "\n",
    "            You need to get the total expected amount to be paid back with \n",
    "            interest for each row, so make a new column for it.\n",
    "\n",
    "            Then predict how much the amount \n",
    "            paid back in 6 months would be.\n",
    "\n",
    "            Use the total expected and the amount after 6 months to get\n",
    "            a percentage of how much has been paid compared to the total                \n",
    "\"\"\"\n",
    "\n",
    "'''triple-quote string contains function: milestone4_task1\n",
    "def milestone4_task1(dataframe: pd.core.frame.DataFrame) -> pd.core.frame.DataFrame:\n",
    "    \"\"\"Remove specific columns from a dataframe depending on which step you choose.\n",
    "\n",
    "    Args:\n",
    "        dataframe pd.core.frame.DataFrame: a dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    def step2_cleanup(dataframe, symbols):\n",
    "        \n",
    "        def conversions(dataframe):\n",
    "            \"\"\"Convert columns to relevant dtypes.\n",
    "            \"\"\"\n",
    "            list_of_to_categorical = ['term','grade','sub_grade', 'employment_length','home_ownership','verification_status','loan_status','payment_plan','purpose','delinq_2yrs','application_type']\n",
    "            list_of_to_boolean = ['policy_code']\n",
    "            list_of_to_float = []\n",
    "            list_of_to_int = []\n",
    "            #print(dataframe['next_payment_date'])\n",
    "            dates_to_convert = ['issue_date','earliest_credit_line','last_payment_date','next_payment_date','last_credit_pull_date']\n",
    "            \n",
    "            dataframe = DT.to_categorical(dataframe, list_of_to_categorical)\n",
    "            dataframe = DT.to_categorical(dataframe, list_of_to_categorical)\n",
    "            dataframe = DT.to_boolean(dataframe, list_of_to_boolean)\n",
    "            dataframe = DT.to_float(dataframe, list_of_to_float)\n",
    "            dataframe = DT.to_int(dataframe, list_of_to_int)\n",
    "            dataframe = DT.convert_dates_to_proper_format(dataframe, dates_to_convert)\n",
    "            \n",
    "            return dataframe\n",
    "        \n",
    "        def DataFrameInfo_class_method_execution(dataframe):\n",
    "        #DataFrameInfo class method execution.\n",
    "            dataframe = DFI.describe_all_columns_to_check_their_datatypes(dataframe)\n",
    "            dataframe = DFI.extract_statistical_values_median_stddev_mean_from_cols_and_dataframe(dataframe)\n",
    "            dataframe = DFI.count_distinct_values_in_categorical_columns(dataframe)\n",
    "            dataframe = DFI.print_out_the_shape_of_the_dataframe(dataframe)\n",
    "            dataframe = DFI.generate_a_count_slash_percentage_count_of_NULL_values_in_each_column(dataframe)\n",
    "            return dataframe\n",
    "        \n",
    "        def Plotting_and_dropping_nulls_from_columns(dataframe):\n",
    "            print(\"Graph of nulls in this dataframe:\\n\")\n",
    "            dataframe = PL.generate_a_plot_for_nulls(dataframe)\n",
    "            dataframe = amount_of_nulls_and_column_drop(dataframe)\n",
    "            return dataframe\n",
    "        \n",
    "        def imputing(dataframe):\n",
    "            dataframe = DFT.impute(dataframe)\n",
    "            return dataframe\n",
    "\n",
    "        def apply_skew_correction(dataframe):\n",
    "            #Applying skew correction\n",
    "            dataframe = PL.skew_correction(dataframe)\n",
    "            return dataframe\n",
    "        \n",
    "        def remove_excess_symbols(dataframe):\n",
    "            #Removing excess symbols\n",
    "            dataframe = DT.excess_symbol_removal(dataframe, symbols)\n",
    "            return dataframe\n",
    "        \n",
    "        \n",
    "        dataframe = conversions(dataframe)\n",
    "        dataframe = DataFrameInfo_class_method_execution(dataframe)\n",
    "        dataframe = Plotting_and_dropping_nulls_from_columns(dataframe)\n",
    "        dataframe = imputing(dataframe)\n",
    "        dataframe = Plotting_and_dropping_nulls_from_columns(dataframe)\n",
    "        dataframe = apply_skew_correction(dataframe)\n",
    "        dataframe = remove_excess_symbols(dataframe) # cant be this one\n",
    "        \n",
    "        return dataframe\n",
    "    \n",
    "    symbols1 = ['id', 'member_id', 'term', 'int_rate', 'instalment', 'grade', 'sub_grade', 'employment_length']\n",
    "    symbols2 = ['verification_status', 'issue_date', 'payment_plan', 'purpose', 'dti', 'delinq_2yrs', 'home_ownership']\n",
    "    symbols3 = ['earliest_credit_line', 'inq_last_6mths', 'open_accounts', 'total_accounts', 'last_payment_date']\n",
    "    symbols4 = ['last_credit_pull_date', 'collections_12_mths_ex_med', 'policy_code', 'application_type', 'annual_inc']\n",
    "    \n",
    "    \n",
    "    symbols_for_step_2 = symbols1 + symbols2 + symbols3 + symbols4 #cleanup assumed the same for both step 1 and 2\n",
    "    \n",
    "    step2_df_clean = step2_cleanup(dataframe, symbols_for_step_2)\n",
    "    return step2_df_clean #these are the same dataframes\n",
    "'''\n",
    "#step2_df_clean = milestone4_task1(datacsv_df)\n",
    "\n",
    "'''triple-quote string containing functions: create_recoveries_df, remove_rows_of_zeros\n",
    "def create_recoveries_df(dataframe):\n",
    "    \"\"\"Create a dataframe from pandas series.\n",
    "\n",
    "    Args:\n",
    "        dataframe (_type_): _description_\n",
    "    \"\"\"\n",
    "    def recoveries_divided_by(dataframe):\n",
    "        \"\"\"Create pandas series from dataframe.\n",
    "\n",
    "        Args:\n",
    "            dataframe (_type_): _description_\n",
    "\n",
    "        Returns:\n",
    "            _type_: _description_\n",
    "        \"\"\"\n",
    "        recoveries_as_a_percentage_of_loan_amount: pd.Series = ((dataframe['recoveries']/dataframe['loan_amount'])*100)\n",
    "        recoveries_as_a_percentage_of_funded_amount: pd.Series = ((dataframe['recoveries']/dataframe['funded_amount'])*100)\n",
    "        recoveries_as_a_percentage_of_funded_amount_inv: pd.Series = ((dataframe['recoveries']/dataframe['funded_amount_inv'])*100)\n",
    "        return recoveries_as_a_percentage_of_loan_amount, recoveries_as_a_percentage_of_funded_amount, recoveries_as_a_percentage_of_funded_amount_inv\n",
    "    a, b, c = recoveries_divided_by(dataframe)\n",
    "    dataframe = pd.DataFrame({'recoveries_as_a_%_of_loan_amount':a, 'recoveries_as_a_%_of_funded_amount':b, 'recoveries_as_a_%_of_funded_amount_inv':c})\n",
    "    return dataframe\n",
    "\n",
    "def remove_rows_of_zeros(dataframe):\n",
    "    \"\"\"Remove rows where there are zeros, return recoveries.\n",
    "\n",
    "    Args:\n",
    "        dataframe (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    dataframe = create_recoveries_df(step1_df_clean)\n",
    "    dataframe = dataframe[(dataframe != 0).any(axis=1)]#remove rows where nothing is there on any of the columns\n",
    "    print(len(dataframe))\n",
    "    return dataframe\n",
    "'''\n",
    "\n",
    "'''triple-quote string containing variables: recoveries_df, recoveries_trimmed_df, etc...\n",
    "#recoveries_df = create_recoveries_df(step1_df_clean)\n",
    "#recoveries_df = remove_rows_of_zeros(recoveries_df)\n",
    "\n",
    "#recoveries_trimmed_df = DFT.trim_by_iqr_limits(recoveries_df, list(recoveries_df.columns))\n",
    "#trim by iqr works, zscore yields empty dataframe.\n",
    "#Too many are trimmed perhaps?\n",
    "\n",
    "#print(recoveries_trimmed_df)\n",
    "#PL.plot_boxplots(recoveries_trimmed_df, ['recoveries_as_a_%_of_loan_amount', 'recoveries_as_a_%_of_funded_amount', 'recoveries_as_a_%_of_funded_amount_inv'])\n",
    "'''\n",
    "\n",
    "print(\"END OF CODE\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
